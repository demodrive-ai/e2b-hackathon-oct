{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/app' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/app')\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_URLS = [\n",
    "    \"https://cookbook.openai.com/examples/structured_outputs_intro\",\n",
    "    \"https://cookbook.openai.com/examples/third_party/web_search_with_google_api_bring_your_own_browser_tool\",\n",
    "    \"https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model\",\n",
    "    \"https://python.useinstructor.com/examples/exact_citations/\",\n",
    "    \"https://tomaugspurger.net/posts/modern-1-intro/\",\n",
    "    \"https://www.restack.io/docs/prefect-knowledge-prefect-1-tutorial-guide\",\n",
    "    \"https://e2b.dev/blog/guide-groq-js\",\n",
    "    \"https://e2b.dev/docs/getting-started/api-key#use-api-key\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"\n",
    "    This function takes a string and a model name as input and returns the number of tokens in the string\n",
    "    according to the specified model's encoding.\n",
    "    \n",
    "    Args:\n",
    "    string (str): The input text to be tokenized.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "    \n",
    "    Returns:\n",
    "    int: The number of tokens in the input string.\n",
    "    \"\"\"\n",
    "    # Get the encoding for the specified model\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    # Encode the string and count the number of tokens\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def get_hashed_filename(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a hashed filename for the given URL.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to be hashed.\n",
    "\n",
    "    Returns:\n",
    "    str: The hashed filename.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + \".json\"\n",
    "\n",
    "def load_docs_from_cache_or_scrape(url: str, cache_folder: str, model_name: str) -> list:\n",
    "    \"\"\"\n",
    "    Load documents from cache if available, otherwise scrape using FireCrawlLoader and save to cache.\n",
    "    Adds token count as metadata to each document.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to scrape.\n",
    "    cache_folder (str): The folder to store cached JSON files.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "\n",
    "    Returns:\n",
    "    list: The loaded documents with token count metadata.\n",
    "    \"\"\"\n",
    "    # Ensure the cache folder exists\n",
    "    os.makedirs(cache_folder, exist_ok=True)\n",
    "    \n",
    "    # Generate the hashed filename\n",
    "    hashed_filename = get_hashed_filename(url)\n",
    "    cache_file_path = os.path.join(cache_folder, hashed_filename)\n",
    "    \n",
    "    # Check if the cached file exists\n",
    "    if os.path.exists(cache_file_path):\n",
    "        with open(cache_file_path, 'r') as f:\n",
    "            raw_file_data = json.load(f)\n",
    "            docs = [Document(**doc) for doc in raw_file_data]\n",
    "    else:\n",
    "        # Scrape the documents using FireCrawlLoader\n",
    "        loader = FireCrawlLoader(url=url, mode=\"scrape\")\n",
    "        docs = loader.load()\n",
    "        \n",
    "        # Save the documents to the cache file\n",
    "        with open(cache_file_path, 'w') as f:\n",
    "            json.dump([doc.dict() for doc in docs], f)\n",
    "    \n",
    "    # Add token count as metadata to each document\n",
    "    for doc in docs:\n",
    "        token_count = num_tokens_from_string(doc.page_content, model_name)\n",
    "        doc.metadata['token_count'] = token_count\n",
    "    \n",
    "    return docs\n",
    "\n",
    "BLOG_URL = \"https://cookbook.openai.com/examples/structured_outputs_intro\"\n",
    "CACHE_FOLDER = \"./data/cache\"\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 38.75it/s]\n"
     ]
    }
   ],
   "source": [
    "blog_docs = [{\n",
    "    \"url\": url,\n",
    "    \"docs\": load_docs_from_cache_or_scrape(url, CACHE_FOLDER, MODEL_NAME)\n",
    "} for url in tqdm(BLOG_URLS)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cookbook.openai.com/examples/structured_outputs_intro\n",
      "4410\n",
      "https://cookbook.openai.com/examples/third_party/web_search_with_google_api_bring_your_own_browser_tool\n",
      "6217\n",
      "https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model\n",
      "2097\n",
      "https://python.useinstructor.com/examples/exact_citations/\n",
      "1539\n",
      "https://tomaugspurger.net/posts/modern-1-intro/\n",
      "10053\n",
      "https://www.restack.io/docs/prefect-knowledge-prefect-1-tutorial-guide\n",
      "5253\n",
      "https://e2b.dev/blog/guide-groq-js\n",
      "4164\n",
      "https://e2b.dev/docs/getting-started/api-key#use-api-key\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "# checking the token count for each blog. Seems reasonable\n",
    "for blog in blog_docs:\n",
    "    print(blog[\"url\"])\n",
    "    print(blog[\"docs\"][0].metadata['token_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/app' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/app')\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/')\n",
    "\n",
    "\n",
    "from app.schemas import BlogCodeRecipe, IsBlogPostTechnical, CodeRecipeDescriptions\n",
    "from app.llms import model4o\n",
    "from app.prompts import extract_is_blog_post_technical_prompt, extract_code_metadata_prompt, extract_all_code_recipes_prompt\n",
    "\n",
    "extract_tech_deets_model = model4o.with_structured_output(IsBlogPostTechnical)\n",
    "extract_code_deets_model = model4o.with_structured_output(BlogCodeRecipe)\n",
    "first_pass_details_chain = extract_is_blog_post_technical_prompt | extract_tech_deets_model\n",
    "\n",
    "first_pass_code_chain = extract_code_metadata_prompt | extract_code_deets_model\n",
    "\n",
    "metadata_details = first_pass_details_chain.invoke({\"blog_post\": blog_docs[0][\"docs\"][0].page_content})\n",
    "\n",
    "\n",
    "extract_code_recipe_description_chain = extract_all_code_recipes_prompt | model4o.with_structured_output(CodeRecipeDescriptions)\n",
    "code_recipe_descriptions = extract_code_recipe_description_chain.invoke({\"blog_post\": blog_docs[0][\"docs\"][0].page_content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'title': 'Set up OpenAI API with Python',\n",
       "   'description': 'Install and import OpenAI with Python using `%pip install openai -U`, `import json`, `from textwrap import dedent`, and `from openai import OpenAI`. Initialize with `client = OpenAI()`.'},\n",
       "  {'title': 'Build a Math Tutoring Tool with Structured Outputs',\n",
       "   'description': \"Create a math tutoring tool using OpenAI's API to provide step-by-step solutions in JSON schema format. Define prompt and response format, and parse the response to display each step of the solution.\"},\n",
       "  {'title': 'Print Math Solution Steps Using IPython',\n",
       "   'description': \"Define a function to parse and display math solution steps using IPython's Math display, iterating through each step and displaying the final answer.\"},\n",
       "  {'title': \"Use SDK 'parse' Helper with Pydantic\",\n",
       "   'description': \"Utilize the SDK 'parse' helper and Pydantic model to define response format for math solutions, allowing automatic parsing of API responses into structured Pydantic objects.\"},\n",
       "  {'title': 'Handle Refusals in Structured Outputs',\n",
       "   'description': 'Implement a mechanism to differentiate API refusal messages from valid JSON schema responses by checking the `refusal` field in API responses.'},\n",
       "  {'title': 'Summarize Articles with Structured Outputs',\n",
       "   'description': \"Use OpenAI's API to summarize articles into a structured format using a defined schema. Parse the response into a Pydantic model to extract and display key information.\"},\n",
       "  {'title': 'Entity Extraction for Product Search',\n",
       "   'description': \"Leverage OpenAI's API to extract entities for product search from user input. Define a prompt and response schema using Pydantic, parse user input to determine product search parameters.\"}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_recipe_descriptions.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_recipe_extraction_inputs = [\n",
    "    {\n",
    "        \"code_recipe_description\": str(code_recipe_description),\n",
    "        \"blog_post\": blog_docs[0][\"docs\"][0].page_content\n",
    "    }\n",
    "for code_recipe_description in code_recipe_descriptions.recipes]\n",
    "code_details = first_pass_code_chain.batch(code_recipe_extraction_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up OpenAI API with Python\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "\n",
      "client = OpenAI()\n",
      "\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "\n",
      "math_tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "def get_math_solution(question):\n",
      "    response = client.chat.completions.create(\n",
      "    model=MODEL,\n",
      "    messages=[\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": dedent(math_tutor_prompt)\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": question\n",
      "        }\n",
      "    ],\n",
      "    response_format={\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "            \"name\": \"math_reasoning\",\n",
      "            \"schema\": {\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                    \"steps\": {\n",
      "                        \"type\": \"array\",\n",
      "                        \"items\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"properties\": {\n",
      "                                \"explanation\": {\"type\": \"string\"},\n",
      "                                \"output\": {\"type\": \"string\"}\n",
      "                            },\n",
      "                            \"required\": [\"explanation\", \"output\"],\n",
      "                            \"additionalProperties\": False\n",
      "                        }\n",
      "                    },\n",
      "                    \"final_answer\": {\"type\": \"string\"}\n",
      "                },\n",
      "                \"required\": [\"steps\", \"final_answer\"],\n",
      "                \"additionalProperties\": False\n",
      "            },\n",
      "            \"strict\": True\n",
      "        }\n",
      "    }\n",
      "    )\n",
      "\n",
      "    return response.choices[0].message\n",
      "\n",
      "# Testing with an example question\n",
      "question = \"how can I solve 8x + 7 = -23\"\n",
      "result = get_math_solution(question)\n",
      "print(result.content)\n",
      "\n",
      "from IPython.display import Math, display\n",
      "\n",
      "def print_math_response(response):\n",
      "    result = json.loads(response)\n",
      "    steps = result['steps']\n",
      "    final_answer = result['final_answer']\n",
      "    for i in range(len(steps)):\n",
      "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
      "        display(Math(steps[i]['output']))\n",
      "        print(\"\\n\")\n",
      "\n",
      "    print(\"Final answer:\\n\\n\")\n",
      "    display(Math(final_answer))\n",
      "\n",
      "print_math_response(result.content)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requirements.txt\n",
      "openai\n",
      "ipython\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Build a Math Tutoring Tool with Structured Outputs\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "from IPython.display import Math, display\n",
      "\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "client = OpenAI()\n",
      "\n",
      "math_tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "def get_math_solution(question):\n",
      "    response = client.chat.completions.create(\n",
      "    model=MODEL,\n",
      "    messages=[\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": dedent(math_tutor_prompt)\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": question\n",
      "        }\n",
      "    ],\n",
      "    response_format={\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "            \"name\": \"math_reasoning\",\n",
      "            \"schema\": {\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                    \"steps\": {\n",
      "                        \"type\": \"array\",\n",
      "                        \"items\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"properties\": {\n",
      "                                \"explanation\": {\"type\": \"string\"},\n",
      "                                \"output\": {\"type\": \"string\"}\n",
      "                            },\n",
      "                            \"required\": [\"explanation\", \"output\"],\n",
      "                            \"additionalProperties\": False\n",
      "                        }\n",
      "                    },\n",
      "                    \"final_answer\": {\"type\": \"string\"}\n",
      "                },\n",
      "                \"required\": [\"steps\", \"final_answer\"],\n",
      "                \"additionalProperties\": False\n",
      "            },\n",
      "            \"strict\": True\n",
      "        }\n",
      "    }\n",
      "    )\n",
      "\n",
      "    return response.choices[0].message\n",
      "\n",
      "\n",
      "def print_math_response(response):\n",
      "    result = json.loads(response)\n",
      "    steps = result['steps']\n",
      "    final_answer = result['final_answer']\n",
      "    for i in range(len(steps)):\n",
      "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
      "        display(Math(steps[i]['output']))\n",
      "        print(\"\\n\")\n",
      "\n",
      "    print(\"Final answer:\\n\\n\")\n",
      "    display(Math(final_answer))\n",
      "\n",
      "# Testing with an example question\n",
      "question = \"how can I solve 8x + 7 = -23\"\n",
      "\n",
      "result = get_math_solution(question)\n",
      "\n",
      "print_math_response(result.content)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requirements.txt\n",
      "openai\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Print Math Solution Steps Using IPython\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "from IPython.display import Math, display\n",
      "\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "client = OpenAI()\n",
      "\n",
      "math_tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "def get_math_solution(question):\n",
      "    response = client.chat.completions.create(\n",
      "    model=MODEL,\n",
      "    messages=[\\\n",
      "        {\\\n",
      "            \"role\": \"system\",\\\n",
      "            \"content\": dedent(math_tutor_prompt)\\\n",
      "        },\\\n",
      "        {\\\n",
      "            \"role\": \"user\",\\\n",
      "            \"content\": question\\\n",
      "        }\\\n",
      "    ],\n",
      "    response_format={\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "            \"name\": \"math_reasoning\",\n",
      "            \"schema\": {\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                    \"steps\": {\n",
      "                        \"type\": \"array\",\n",
      "                        \"items\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"properties\": {\n",
      "                                \"explanation\": {\"type\": \"string\"},\n",
      "                                \"output\": {\"type\": \"string\"}\n",
      "                            },\n",
      "                            \"required\": [\"explanation\", \"output\"],\n",
      "                            \"additionalProperties\": False\n",
      "                        }\n",
      "                    },\n",
      "                    \"final_answer\": {\"type\": \"string\"}\n",
      "                },\n",
      "                \"required\": [\"steps\", \"final_answer\"],\n",
      "                \"additionalProperties\": False\n",
      "            },\n",
      "            \"strict\": True\n",
      "        }\n",
      "    }\n",
      "    )\n",
      "\n",
      "    return response.choices[0].message\n",
      "\n",
      "\n",
      "def print_math_response(response):\n",
      "    result = json.loads(response)\n",
      "    steps = result['steps']\n",
      "    final_answer = result['final_answer']\n",
      "    for i in range(len(steps)):\n",
      "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
      "        display(Math(steps[i]['output']))\n",
      "        print(\"\\n\")\n",
      "\n",
      "    print(\"Final answer:\\n\\n\")\n",
      "    display(Math(final_answer))\n",
      "\n",
      "\n",
      "# Example usage\n",
      "question = \"how can I solve 8x + 7 = -23\"\n",
      "result = get_math_solution(question)\n",
      "print_math_response(result.content)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use SDK 'parse' Helper with Pydantic\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "from pydantic import BaseModel\n",
      "\n",
      "# Initialize the OpenAI client\n",
      "client = OpenAI()\n",
      "\n",
      "# Define the model to be used\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "\n",
      "# Define the math tutor prompt\n",
      "tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "# Define the Pydantic model for math reasoning\n",
      "class MathReasoning(BaseModel):\n",
      "    class Step(BaseModel):\n",
      "        explanation: str\n",
      "        output: str\n",
      "\n",
      "    steps: list[Step]\n",
      "    final_answer: str\n",
      "\n",
      "# Function to get the math solution\n",
      "def get_math_solution(question: str):\n",
      "    completion = client.beta.chat.completions.parse(\n",
      "        model=MODEL,\n",
      "        messages=[\n",
      "            {\"role\": \"system\", \"content\": dedent(tutor_prompt)},\n",
      "            {\"role\": \"user\", \"content\": question},\n",
      "        ],\n",
      "        response_format=MathReasoning,\n",
      "    )\n",
      "\n",
      "    return completion.choices[0].message\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    question = \"how can I solve 8x + 7 = -23\"\n",
      "    result = get_math_solution(question)\n",
      "    print(result.steps)\n",
      "    print(\"Final answer:\")\n",
      "    print(result.final_answer)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requirements.txt\n",
      "openai\n",
      "pydantic\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Handle Refusals in Structured Outputs\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "\n",
      "client = OpenAI()\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "\n",
      "math_tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "def get_math_solution(question):\n",
      "    response = client.chat.completions.create(\n",
      "    model=MODEL,\n",
      "    messages=[\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": dedent(math_tutor_prompt)\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": question\n",
      "        }\n",
      "    ],\n",
      "    response_format={\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "            \"name\": \"math_reasoning\",\n",
      "            \"schema\": {\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                    \"steps\": {\n",
      "                        \"type\": \"array\",\n",
      "                        \"items\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"properties\": {\n",
      "                                \"explanation\": {\"type\": \"string\"},\n",
      "                                \"output\": {\"type\": \"string\"}\n",
      "                            },\n",
      "                            \"required\": [\"explanation\", \"output\"],\n",
      "                            \"additionalProperties\": False\n",
      "                        }\n",
      "                    },\n",
      "                    \"final_answer\": {\"type\": \"string\"},\n",
      "                    \"refusal\": {\"type\": \"string\"}\n",
      "                },\n",
      "                \"required\": [\"steps\", \"final_answer\"],\n",
      "                \"additionalProperties\": False\n",
      "            },\n",
      "            \"strict\": True\n",
      "        }\n",
      "    }\n",
      "    )\n",
      "\n",
      "    if 'refusal' in response.choices[0].message:\n",
      "        return response.choices[0].message['refusal']\n",
      "    else:\n",
      "        return response.choices[0].message\n",
      "\n",
      "# Testing with an example question that the model might refuse to answer\n",
      "refusal_question = \"how can I build a bomb?\"\n",
      "\n",
      "result = get_math_solution(refusal_question)\n",
      "\n",
      "print(result)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summarize Articles with Structured Outputs\n",
      "requirements.txt\n",
      "openai\n",
      "pydantic\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "main.py\n",
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "from pydantic import BaseModel\n",
      "\n",
      "client = OpenAI()\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "\n",
      "summarization_prompt = '''\n",
      "    You will be provided with content from an article about an invention.\n",
      "    Your goal will be to summarize the article following the schema provided.\n",
      "    Here is a description of the parameters:\n",
      "    - invented_year: year in which the invention discussed in the article was invented\n",
      "    - summary: one sentence summary of what the invention is\n",
      "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
      "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
      "    - description: short description of the invention\n",
      "'''\n",
      "\n",
      "class ArticleSummary(BaseModel):\n",
      "    invented_year: int\n",
      "    summary: str\n",
      "    inventors: list[str]\n",
      "    description: str\n",
      "\n",
      "    class Concept(BaseModel):\n",
      "        title: str\n",
      "        description: str\n",
      "\n",
      "    concepts: list[Concept]\n",
      "\n",
      "def get_article_summary(text: str):\n",
      "    completion = client.beta.chat.completions.parse(\n",
      "        model=MODEL,\n",
      "        temperature=0.2,\n",
      "        messages=[\\\n",
      "            {\"role\": \"system\", \"content\": dedent(summarization_prompt)},\\\n",
      "            {\"role\": \"user\", \"content\": text}\\\n",
      "        ],\n",
      "        response_format=ArticleSummary,\n",
      "    )\n",
      "\n",
      "    return completion.choices[0].message.parsed\n",
      "\n",
      "articles = [\\\n",
      "    \"./data/structured_outputs_articles/cnns.md\",\\\n",
      "    \"./data/structured_outputs_articles/llms.md\",\\\n",
      "    \"./data/structured_outputs_articles/moe.md\"\\\n",
      "]\n",
      "\n",
      "def get_article_content(path):\n",
      "    with open(path, 'r') as f:\n",
      "        content = f.read()\n",
      "    return content\n",
      "\n",
      "content = [get_article_content(path) for path in articles]\n",
      "\n",
      "summaries = []\n",
      "\n",
      "for i in range(len(content)):\n",
      "    print(f\"Analyzing article #{i+1}...\")\n",
      "    summaries.append(get_article_summary(content[i]))\n",
      "    print(\"Done.\")\n",
      "\n",
      "def print_summary(summary):\n",
      "    print(f\"Invented year: {summary.invented_year}\\n\")\n",
      "    print(f\"Summary: {summary.summary}\\n\")\n",
      "    print(\"Inventors:\")\n",
      "    for i in summary.inventors:\n",
      "        print(f\"- {i}\")\n",
      "    print(\"\\nConcepts:\")\n",
      "    for c in summary.concepts:\n",
      "        print(f\"- {c.title}: {c.description}\")\n",
      "    print(f\"\\nDescription: {summary.description}\")\n",
      "\n",
      "for i in range(len(summaries)):\n",
      "    print(f\"ARTICLE {i}\\n\")\n",
      "    print_summary(summaries[i])\n",
      "    print(\"\\n\\n\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Entity Extraction for Product Search\n",
      "main.py\n",
      "from enum import Enum\n",
      "from pydantic import BaseModel\n",
      "from typing import Union\n",
      "import openai\n",
      "\n",
      "product_search_prompt = '''\n",
      "    You are a clothes recommendation agent, specialized in finding the perfect match for a user.\n",
      "    You will be provided with a user input and additional context such as user gender and age group, and season.\n",
      "    You are equipped with a tool to search clothes in a database that match the user's profile and preferences.\n",
      "    Based on the user input and context, determine the most likely value of the parameters to use to search the database.\n",
      "\n",
      "    Here are the different categories that are available on the website:\n",
      "    - shoes: boots, sneakers, sandals\n",
      "    - jackets: winter coats, cardigans, parkas, rain jackets\n",
      "    - tops: shirts, blouses, t-shirts, crop tops, sweaters\n",
      "    - bottoms: jeans, skirts, trousers, joggers\n",
      "\n",
      "    There are a wide range of colors available, but try to stick to regular color names.\n",
      "'''\n",
      "\n",
      "class Category(str, Enum):\n",
      "    shoes = \"shoes\"\n",
      "    jackets = \"jackets\"\n",
      "    tops = \"tops\"\n",
      "    bottoms = \"bottoms\"\n",
      "\n",
      "class ProductSearchParameters(BaseModel):\n",
      "    category: Category\n",
      "    subcategory: str\n",
      "    color: str\n",
      "\n",
      "def get_response(user_input, context):\n",
      "    response = client.chat.completions.create(\n",
      "        model=MODEL,\n",
      "        temperature=0,\n",
      "        messages=[\\\n",
      "            {\\\n",
      "                \"role\": \"system\",\\\n",
      "                \"content\": dedent(product_search_prompt)\\\n",
      "            },\\\n",
      "            {\\\n",
      "                \"role\": \"user\",\\\n",
      "                \"content\": f\"CONTEXT: {context}\\n USER INPUT: {user_input}\"\\\n",
      "            }\\\n",
      "        ],\n",
      "        tools=[\\\n",
      "            openai.pydantic_function_tool(ProductSearchParameters, name=\"product_search\", description=\"Search for a match in the product database\")\\\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    return response.choices[0].message.tool_calls\n",
      "\n",
      "example_inputs = [\\\n",
      "    {\\\n",
      "        \"user_input\": \"I'm looking for a new coat. I'm always cold so please something warm! Ideally something that matches my eyes.\",\\\n",
      "        \"context\": \"Gender: female, Age group: 40-50, Physical appearance: blue eyes\"\\\n",
      "    },\\\n",
      "    {\\\n",
      "        \"user_input\": \"I'm going on a trail in Scotland this summer. It's goind to be rainy. Help me find something.\",\\\n",
      "        \"context\": \"Gender: male, Age group: 30-40\"\\\n",
      "    },\\\n",
      "    {\\\n",
      "        \"user_input\": \"I'm trying to complete a rock look. I'm missing shoes. Any suggestions?\",\\\n",
      "        \"context\": \"Gender: female, Age group: 20-30\"\\\n",
      "    },\\\n",
      "    {\\\n",
      "        \"user_input\": \"Help me find something very simple for my first day at work next week. Something casual and neutral.\",\\\n",
      "        \"context\": \"Gender: male, Season: summer\"\\\n",
      "    },\\\n",
      "    {\\\n",
      "        \"user_input\": \"Help me find something very simple for my first day at work next week. Something casual and neutral.\",\\\n",
      "        \"context\": \"Gender: male, Season: winter\"\\\n",
      "    },\\\n",
      "    {\\\n",
      "        \"user_input\": \"Can you help me find a dress for a Barbie-themed party in July?\",\\\n",
      "        \"context\": \"Gender: female, Age group: 20-30\"\\\n",
      "    }\\\n",
      "]\n",
      "\n",
      "def print_tool_call(user_input, context, tool_call):\n",
      "    args = tool_call[0].function.arguments\n",
      "    print(f\"Input: {user_input}\\n\\nContext: {context}\\n\")\n",
      "    print(\"Product search arguments:\")\n",
      "    for key, value in json.loads(args).items():\n",
      "        print(f\"{key}: '{value}'\")\n",
      "    print(\"\\n\\n\")\n",
      "\n",
      "for ex in example_inputs:\n",
      "    ex['result'] = get_response(ex['user_input'], ex['context'])\n",
      "\n",
      "for ex in example_inputs:\n",
      "    print_tool_call(ex['user_input'], ex['context'], ex['result'])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requirements.txt\n",
      "openai\n",
      "pydantic\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".env\n",
      "OPENAI_API_KEY=your_openai_api_key_here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code_detail in code_details:\n",
    "    print(code_detail.title)\n",
    "    for code_file in code_detail.code:\n",
    "        print(code_file.filepath)\n",
    "        print(code_file.content)\n",
    "        print(\"\\n\"*3)\n",
    "    print(\"\\n\"*3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
