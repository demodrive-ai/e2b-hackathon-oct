{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "if \"/Users/nehiljain/code/e2b-hackathon-oct/app\" not in sys.path:\n",
    "    sys.path.append(\"/Users/nehiljain/code/e2b-hackathon-oct/app\")\n",
    "if \"/Users/nehiljain/code/e2b-hackathon-oct/\" not in sys.path:\n",
    "    sys.path.append(\"/Users/nehiljain/code/e2b-hackathon-oct/\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_URLS = [\"https://e2b.dev/blog/python-code-interpreter-with-o1-and-gpt-4o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"\n",
    "    This function takes a string and a model name as input and returns the number of tokens in the string\n",
    "    according to the specified model's encoding.\n",
    "\n",
    "    Args:\n",
    "    string (str): The input text to be tokenized.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of tokens in the input string.\n",
    "    \"\"\"\n",
    "    # Get the encoding for the specified model\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    # Encode the string and count the number of tokens\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def get_hashed_filename(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a hashed filename for the given URL.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to be hashed.\n",
    "\n",
    "    Returns:\n",
    "    str: The hashed filename.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + \".json\"\n",
    "\n",
    "\n",
    "def load_docs_from_cache_or_scrape(\n",
    "    url: str, cache_folder: str, model_name: str\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Load documents from cache if available, otherwise scrape using FireCrawlLoader and save to cache.\n",
    "    Adds token count as metadata to each document.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to scrape.\n",
    "    cache_folder (str): The folder to store cached JSON files.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "\n",
    "    Returns:\n",
    "    list: The loaded documents with token count metadata.\n",
    "    \"\"\"\n",
    "    # Ensure the cache folder exists\n",
    "    os.makedirs(cache_folder, exist_ok=True)\n",
    "\n",
    "    # Generate the hashed filename\n",
    "    hashed_filename = get_hashed_filename(url)\n",
    "    cache_file_path = os.path.join(cache_folder, hashed_filename)\n",
    "\n",
    "    # Check if the cached file exists\n",
    "    if os.path.exists(cache_file_path):\n",
    "        with open(cache_file_path, \"r\") as f:\n",
    "            raw_file_data = json.load(f)\n",
    "            docs = [Document(**doc) for doc in raw_file_data]\n",
    "    else:\n",
    "        # Scrape the documents using FireCrawlLoader\n",
    "        loader = FireCrawlLoader(url=url, mode=\"scrape\")\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Save the documents to the cache file\n",
    "        with open(cache_file_path, \"w\") as f:\n",
    "            json.dump([doc.dict() for doc in docs], f)\n",
    "\n",
    "    # Add token count as metadata to each document\n",
    "    for doc in docs:\n",
    "        token_count = num_tokens_from_string(doc.page_content, model_name)\n",
    "        doc.metadata[\"token_count\"] = token_count\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "BLOG_URL = \"https://cookbook.openai.com/examples/structured_outputs_intro\"\n",
    "CACHE_FOLDER = \"./data/cache\"\n",
    "MODEL_NAME = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_docs = [\n",
    "    {\"url\": url, \"docs\": load_docs_from_cache_or_scrape(url, CACHE_FOLDER, MODEL_NAME)}\n",
    "    for url in tqdm(BLOG_URLS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the token count for each blog. Seems reasonable\n",
    "for blog in blog_docs:\n",
    "    print(blog[\"url\"])\n",
    "    print(blog[\"docs\"][0].metadata[\"token_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"/Users/nehiljain/code/e2b-hackathon-oct/app\" not in sys.path:\n",
    "    sys.path.append(\"/Users/nehiljain/code/e2b-hackathon-oct/app\")\n",
    "if \"/Users/nehiljain/code/e2b-hackathon-oct/\" not in sys.path:\n",
    "    sys.path.append(\"/Users/nehiljain/code/e2b-hackathon-oct/\")\n",
    "\n",
    "\n",
    "from app.schemas import BlogCodeRecipe, IsBlogPostTechnical, CodeRecipeDescriptions\n",
    "from app.llms import model4o\n",
    "from app.prompts import (\n",
    "    extract_is_blog_post_technical_prompt,\n",
    "    extract_code_metadata_prompt,\n",
    "    extract_all_code_recipes_prompt,\n",
    ")\n",
    "\n",
    "extract_tech_deets_model = model4o.with_structured_output(IsBlogPostTechnical)\n",
    "extract_code_deets_model = model4o.with_structured_output(BlogCodeRecipe)\n",
    "first_pass_details_chain = (\n",
    "    extract_is_blog_post_technical_prompt | extract_tech_deets_model\n",
    ")\n",
    "\n",
    "first_pass_code_chain = extract_code_metadata_prompt | extract_code_deets_model\n",
    "\n",
    "metadata_details = first_pass_details_chain.invoke(\n",
    "    {\"blog_post\": blog_docs[-1][\"docs\"][0].page_content}\n",
    ")\n",
    "\n",
    "\n",
    "extract_code_recipe_description_chain = (\n",
    "    extract_all_code_recipes_prompt\n",
    "    | model4o.with_structured_output(CodeRecipeDescriptions)\n",
    ")\n",
    "code_recipe_descriptions = extract_code_recipe_description_chain.invoke(\n",
    "    {\"blog_post\": blog_docs[-1][\"docs\"][0].page_content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_recipe_descriptions.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_recipe_extraction_inputs = [\n",
    "    {\n",
    "        \"code_recipe_description\": str(code_recipe_description),\n",
    "        \"blog_post\": blog_docs[0][\"docs\"][0].page_content,\n",
    "    }\n",
    "    for code_recipe_description in code_recipe_descriptions.recipes\n",
    "]\n",
    "code_details = first_pass_code_chain.batch(code_recipe_extraction_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blog_docs[-1][\"docs\"][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.e2b_runner import run_code_project\n",
    "from app.schemas import BlogCodeRecipe, CodeFile\n",
    "\n",
    "\n",
    "def update_env_file(blog_code_recipe: BlogCodeRecipe, env_content: str):\n",
    "    # Parse the env_content into a dictionary\n",
    "    env_dict = dict(line.split(\"=\") for line in env_content.strip().split(\"\\n\"))\n",
    "\n",
    "    # Check if there is a .env file in the blog_code_recipe\n",
    "    for code_file in blog_code_recipe.code:\n",
    "        if code_file.filepath == \".env\":\n",
    "            # Update the .env file content with the values from env_content\n",
    "            env_lines = code_file.content.split(\"\\n\")\n",
    "            updated_env_lines = []\n",
    "            existing_keys = set()\n",
    "            for line in env_lines:\n",
    "                if line.strip() and \"=\" in line:\n",
    "                    key, _ = line.split(\"=\", 1)\n",
    "                    existing_keys.add(key)\n",
    "                    if key in env_dict:\n",
    "                        updated_env_lines.append(f\"{key}={env_dict[key]}\")\n",
    "                    else:\n",
    "                        updated_env_lines.append(line)\n",
    "                else:\n",
    "                    updated_env_lines.append(line)\n",
    "\n",
    "            # Add new keys from env_dict that don't exist in the current .env file\n",
    "            for key, value in env_dict.items():\n",
    "                if key not in existing_keys:\n",
    "                    updated_env_lines.append(f\"{key}={value}\")\n",
    "\n",
    "            code_file.content = \"\\n\".join(updated_env_lines)\n",
    "            break\n",
    "\n",
    "\n",
    "env_content = \"\"\"\n",
    "... INPUT HERE\n",
    "\"\"\"\n",
    "\n",
    "blog_recipe_to_test = code_details[0]\n",
    "update_env_file(blog_recipe_to_test, env_content)\n",
    "print(f\"Running code project: {blog_recipe_to_test.title}\")\n",
    "result = run_code_project(blog_recipe_to_test)\n",
    "print(f\"Exit Code: {result.exit_code}\")\n",
    "print(f\"Standard Output: {result.stdout}\")\n",
    "print(f\"Standard Error: {result.stderr}\")\n",
    "print(\"\\n\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for blog_recipe_to_test in code_details:\n",
    "#     print(f\"Testing : {blog_recipe_to_test.title}\")\n",
    "#     update_env_file(blog_recipe_to_test, env_content)\n",
    "#     print(f\"Running code project: {blog_recipe_to_test.title}\")\n",
    "#     result = run_code_project(blog_recipe_to_test)\n",
    "#     print(f\"Exit Code: {result.exit_code}\")\n",
    "#     print(f\"Standard Output: {result.stdout}\")\n",
    "#     print(f\"Standard Error: {result.stderr}\")\n",
    "#     print(\"\\n\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
