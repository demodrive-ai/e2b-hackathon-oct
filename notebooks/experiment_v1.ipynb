{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/app' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/app')\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_URLS = [\n",
    "    \"https://cookbook.openai.com/examples/structured_outputs_intro\",\n",
    "    \"https://cookbook.openai.com/examples/third_party/web_search_with_google_api_bring_your_own_browser_tool\",\n",
    "    \"https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model\",\n",
    "    \"https://python.useinstructor.com/examples/exact_citations/\",\n",
    "    \"https://tomaugspurger.net/posts/modern-1-intro/\",\n",
    "    \"https://www.restack.io/docs/prefect-knowledge-prefect-1-tutorial-guide\",\n",
    "    \"https://e2b.dev/blog/guide-groq-js\",\n",
    "    \"https://e2b.dev/docs/getting-started/api-key#use-api-key\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"\n",
    "    This function takes a string and a model name as input and returns the number of tokens in the string\n",
    "    according to the specified model's encoding.\n",
    "    \n",
    "    Args:\n",
    "    string (str): The input text to be tokenized.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "    \n",
    "    Returns:\n",
    "    int: The number of tokens in the input string.\n",
    "    \"\"\"\n",
    "    # Get the encoding for the specified model\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    # Encode the string and count the number of tokens\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def get_hashed_filename(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a hashed filename for the given URL.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to be hashed.\n",
    "\n",
    "    Returns:\n",
    "    str: The hashed filename.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + \".json\"\n",
    "\n",
    "def load_docs_from_cache_or_scrape(url: str, cache_folder: str, model_name: str) -> list:\n",
    "    \"\"\"\n",
    "    Load documents from cache if available, otherwise scrape using FireCrawlLoader and save to cache.\n",
    "    Adds token count as metadata to each document.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to scrape.\n",
    "    cache_folder (str): The folder to store cached JSON files.\n",
    "    model_name (str): The name of the OpenAI model to determine the encoding.\n",
    "\n",
    "    Returns:\n",
    "    list: The loaded documents with token count metadata.\n",
    "    \"\"\"\n",
    "    # Ensure the cache folder exists\n",
    "    os.makedirs(cache_folder, exist_ok=True)\n",
    "    \n",
    "    # Generate the hashed filename\n",
    "    hashed_filename = get_hashed_filename(url)\n",
    "    cache_file_path = os.path.join(cache_folder, hashed_filename)\n",
    "    \n",
    "    # Check if the cached file exists\n",
    "    if os.path.exists(cache_file_path):\n",
    "        with open(cache_file_path, 'r') as f:\n",
    "            raw_file_data = json.load(f)\n",
    "            docs = [Document(**doc) for doc in raw_file_data]\n",
    "    else:\n",
    "        # Scrape the documents using FireCrawlLoader\n",
    "        loader = FireCrawlLoader(url=url, mode=\"scrape\")\n",
    "        docs = loader.load()\n",
    "        \n",
    "        # Save the documents to the cache file\n",
    "        with open(cache_file_path, 'w') as f:\n",
    "            json.dump([doc.dict() for doc in docs], f)\n",
    "    \n",
    "    # Add token count as metadata to each document\n",
    "    for doc in docs:\n",
    "        token_count = num_tokens_from_string(doc.page_content, model_name)\n",
    "        doc.metadata['token_count'] = token_count\n",
    "    \n",
    "    return docs\n",
    "\n",
    "BLOG_URL = \"https://cookbook.openai.com/examples/structured_outputs_intro\"\n",
    "CACHE_FOLDER = \"./data/cache\"\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 27.39it/s]\n"
     ]
    }
   ],
   "source": [
    "blog_docs = [{\n",
    "    \"url\": url,\n",
    "    \"docs\": load_docs_from_cache_or_scrape(url, CACHE_FOLDER, MODEL_NAME)\n",
    "} for url in tqdm(BLOG_URLS)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cookbook.openai.com/examples/structured_outputs_intro\n",
      "4410\n",
      "https://cookbook.openai.com/examples/third_party/web_search_with_google_api_bring_your_own_browser_tool\n",
      "6217\n",
      "https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model\n",
      "2097\n",
      "https://python.useinstructor.com/examples/exact_citations/\n",
      "1539\n",
      "https://tomaugspurger.net/posts/modern-1-intro/\n",
      "10053\n",
      "https://www.restack.io/docs/prefect-knowledge-prefect-1-tutorial-guide\n",
      "5253\n",
      "https://e2b.dev/blog/guide-groq-js\n",
      "4164\n",
      "https://e2b.dev/docs/getting-started/api-key#use-api-key\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "# checking the token count for each blog. Seems reasonable\n",
    "for blog in blog_docs:\n",
    "    print(blog[\"url\"])\n",
    "    print(blog[\"docs\"][0].metadata['token_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/app' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/app')\n",
    "if '/Users/nehiljain/code/e2b-hackathon-oct/' not in sys.path:\n",
    "    sys.path.append('/Users/nehiljain/code/e2b-hackathon-oct/')\n",
    "\n",
    "\n",
    "from app.schemas import BlogCodeProject, IsBlogPostTechnical\n",
    "from app.llms import model4o\n",
    "from app.prompts import extract_is_blog_post_technical_prompt, extract_code_metadata_prompt\n",
    "\n",
    "extract_tech_deets_model = model4o.with_structured_output(IsBlogPostTechnical)\n",
    "extract_code_deets_model = model4o.with_structured_output(BlogCodeProject)\n",
    "first_pass_details_chain = extract_is_blog_post_technical_prompt | extract_tech_deets_model\n",
    "\n",
    "first_pass_code_chain = extract_code_metadata_prompt | extract_code_deets_model\n",
    "\n",
    "metadata_details = first_pass_details_chain.invoke({\"blog_post\": blog_docs[0][\"docs\"][0].page_content})\n",
    "\n",
    "code_details = first_pass_code_chain.invoke({\"blog_post\": blog_docs[0][\"docs\"][0].page_content})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Example 1: Math tutor',\n",
       " 'published_at': datetime.datetime(2024, 8, 6, 0, 0, tzinfo=TzInfo(UTC)),\n",
       " 'description': 'The script demonstrates how to use the OpenAI API to build a math tutoring tool that generates a step-by-step solution to math problems. It utilizes the Structured Outputs feature to ensure the response follows a defined JSON schema, which details the steps and final answer to the problem provided by the user.',\n",
       " 'code': 'import json\\nfrom textwrap import dedent\\nfrom openai import OpenAI\\nclient = OpenAI()\\n\\nMODEL = \"gpt-4o-2024-08-06\"\\n\\nmath_tutor_prompt = \\'\\'\\'\\n    You are a helpful math tutor. You will be provided with a math problem,\\n    and your goal will be to output a step by step solution, along with a final answer.\\n    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\\n\\'\\'\\'\\n\\ndef get_math_solution(question):\\n    response = client.chat.completions.create(\\n    model=MODEL,\\n    messages=[        \\n        {            \\n            \"role\": \"system\",            \\n            \"content\": dedent(math_tutor_prompt)        \\n        },        \\n        {            \\n            \"role\": \"user\",            \\n            \"content\": question        \\n        }    \\n    ],\\n    response_format={\\n        \"type\": \"json_schema\",\\n        \"json_schema\": {\\n            \"name\": \"math_reasoning\",\\n            \"schema\": {\\n                \"type\": \"object\",\\n                \"properties\": {\\n                    \"steps\": {\\n                        \"type\": \"array\",\\n                        \"items\": {\\n                            \"type\": \"object\",\\n                            \"properties\": {\\n                                \"explanation\": {\"type\": \"string\"},\\n                                \"output\": {\"type\": \"string\"}\\n                            },\\n                            \"required\": [\"explanation\", \"output\"],\\n                            \"additionalProperties\": False\\n                        }\\n                    },\\n                    \"final_answer\": {\"type\": \"string\"}\\n                },\\n                \"required\": [\"steps\", \"final_answer\"],\\n                \"additionalProperties\": False\\n            },\\n            \"strict\": True\\n        }\\n    }\\n    )\\n\\n    return response.choices[0].message\\n\\n# Testing with an example question\\nquestion = \"how can I solve 8x + 7 = -23\"\\n\\nresult = get_math_solution(question)\\n\\nprint(result.content)\\n\\nfrom IPython.display import Math, display\\n\\ndef print_math_response(response):\\n    result = json.loads(response)\\n    steps = result[\\'steps\\']\\n    final_answer = result[\\'final_answer\\']\\n    for i in range(len(steps)):\\n        print(f\"Step {i+1}: {steps[i][\\'explanation\\']}\\\\n\")\\n        display(Math(steps[i][\\'output\\']))\\n        print(\"\\\\n\")\\n\\n    print(\"Final answer:\\\\n\\\\n\")\\n    display(Math(final_answer))\\n\\nprint_math_response(result.content)',\n",
       " 'language': <LanguageEnum.python: 'python'>,\n",
       " 'success_criteria': 'The code successfully communicates with the OpenAI API to generate a structured solution to a math problem, providing both the steps and the final answer in a manner that can be programmatically accessed and displayed.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_details.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "from textwrap import dedent\n",
      "from openai import OpenAI\n",
      "client = OpenAI()\n",
      "\n",
      "MODEL = \"gpt-4o-2024-08-06\"\n",
      "\n",
      "math_tutor_prompt = '''\n",
      "    You are a helpful math tutor. You will be provided with a math problem,\n",
      "    and your goal will be to output a step by step solution, along with a final answer.\n",
      "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
      "'''\n",
      "\n",
      "def get_math_solution(question):\n",
      "    response = client.chat.completions.create(\n",
      "    model=MODEL,\n",
      "    messages=[        \n",
      "        {            \n",
      "            \"role\": \"system\",            \n",
      "            \"content\": dedent(math_tutor_prompt)        \n",
      "        },        \n",
      "        {            \n",
      "            \"role\": \"user\",            \n",
      "            \"content\": question        \n",
      "        }    \n",
      "    ],\n",
      "    response_format={\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "            \"name\": \"math_reasoning\",\n",
      "            \"schema\": {\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                    \"steps\": {\n",
      "                        \"type\": \"array\",\n",
      "                        \"items\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"properties\": {\n",
      "                                \"explanation\": {\"type\": \"string\"},\n",
      "                                \"output\": {\"type\": \"string\"}\n",
      "                            },\n",
      "                            \"required\": [\"explanation\", \"output\"],\n",
      "                            \"additionalProperties\": False\n",
      "                        }\n",
      "                    },\n",
      "                    \"final_answer\": {\"type\": \"string\"}\n",
      "                },\n",
      "                \"required\": [\"steps\", \"final_answer\"],\n",
      "                \"additionalProperties\": False\n",
      "            },\n",
      "            \"strict\": True\n",
      "        }\n",
      "    }\n",
      "    )\n",
      "\n",
      "    return response.choices[0].message\n",
      "\n",
      "# Testing with an example question\n",
      "question = \"how can I solve 8x + 7 = -23\"\n",
      "\n",
      "result = get_math_solution(question)\n",
      "\n",
      "print(result.content)\n",
      "\n",
      "from IPython.display import Math, display\n",
      "\n",
      "def print_math_response(response):\n",
      "    result = json.loads(response)\n",
      "    steps = result['steps']\n",
      "    final_answer = result['final_answer']\n",
      "    for i in range(len(steps)):\n",
      "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
      "        display(Math(steps[i]['output']))\n",
      "        print(\"\\n\")\n",
      "\n",
      "    print(\"Final answer:\\n\\n\")\n",
      "    display(Math(final_answer))\n",
      "\n",
      "print_math_response(result.content)\n"
     ]
    }
   ],
   "source": [
    "print(code_details.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
